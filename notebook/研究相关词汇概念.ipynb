{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## logits\n",
    "但在深度学习中，logits就是最终的全连接层的输出，而非其本意。通常神经网络中都是先有logits，而后通过sigmoid函数或者softmax函数得到概率 [公式] 的，所以大部分情况下都无需用到logit函数的表达式。\n",
    "\n",
    "## logit函数\n",
    "$$L(p)=ln \\frac{p}{1-p}$$\n",
    "是sigmoid函数（标准logistic函数）的反函数，目的是将取值范围在$[0,1]$内的概率映射到实数域$[-inf,inf]$的函数，如果p=0.5，函数值为0,P<0.5，函数值为负，p>0.5，函数值为正。反过来softmax和sigmoid则是将$[-inf,inf]$映射到$[0,1]$。\n",
    "\n",
    "## sigmoid函数\n",
    "$$p(x)=\\frac{1}{1+e^{-x}}$$\n",
    "\n",
    "## sigmoid_cross_entropy_with_logits()\n",
    "代码 ：\n",
    "```python\n",
    "tf.nn.sigmoid_cross_entropy_with_logits(labels=None, logits=None, name=None)\n",
    "```\n",
    "计算网络输出logits和标签labels的sigmoid cross entropy loss（任务的类与类之间不互斥）\n",
    "\n",
    "## tf.reduce_sum()\n",
    "**axis是多维数组每个维度的坐标**最外层的axis是0，越往里越大。\n",
    "\n",
    "`tf.reduce_sum(a,axis=1)`就是将axis=1(从外往里第二个维度)的数组相加的结果，并去掉一个维度。\n",
    "\n",
    "**axis为负数时表示从内往外倒数第x个维度**\n",
    "\n",
    "reduce表示“归约”如果代码是`tf.reduce_sum(a,axis=1,keepdims=True)`表示不归约，即不去掉axis=1的维度，单纯求和。\n",
    "\n",
    "`tf.reduce_sum(a,[0,1])`表示先对0维求和再对1维求和。\n",
    "\n",
    "## Evidence Lower BOund（ELBO） loss 证据下界损失函数\n",
    "$$\\log p(x)\\geq E_{q_\\phi (z|x)}[\\log p_\\phi (x|z)]-D_{KL}[q_\\phi (z|x)\\parallel p(z)]$$\n",
    "\n",
    "## cross entropy交叉熵\n",
    "可以用来表示从事件A的角度看，如何描述事件B\n",
    "\n",
    "## KL散度(KLダイバージェンス)\n",
    "可以用来表示从事件A的角度来看，事件B有多大不同。KL散度也可以被用于计算代价，而在特定情况下最小化KL散度等价于最小化交叉熵。而交叉熵的运算更简单，所以常用于计算代价。\n",
    "\n",
    "## 元学习meta-learning（有趣的研究方向）\n",
    "为了解决学习如何学习的问题。即通过另一个模型来针对神经网络中的初始参数和优化器参数进行调整，从而实现神经网络较好的学习效率。\n",
    "+ 机器学习与元学习的区别：\n",
    "    + machine learning：通过训练数据，学习到输入$X$与输出$Y$之间的映射，从而找到函数$f$，使得$y=f(x)$\n",
    "    + meta learning:通过很多的训练任务$T$及对应的训练数据$D，找到函数$F$。$F可以输出一个函数$f$，用于新的任务。\n",
    "\n",
    "## t-SNE\n",
    "是一种降维技术，用于在二维或三维的低维空间中表示高维数据集，从而使其可视化。与其他降维算法(如PCA)相比，t-SNE创建了一个缩小的特征空间，相似的样本由附近的点建模，不相似的样本由高概率的远点建模。在高水平上，t-SNE为高维样本构建了一个概率分布，相似的样本被选中的可能性很高，而不同的点被选中的可能性极小。然后，t-SNE为低维嵌入中的点定义了相似的分布。最后，t-SNE最小化了两个分布之间关于嵌入点位置的Kullback-Leibler（KL)散度。\n",
    "\n",
    "\n",
    "## Normalizing flows(标准化流)\n",
    "假设我们想生成人脸，但我们并不知道人脸图片在高维空间D的分布，用一个简单的分布$p(z)$，从中采样出一个向量$z$，让它通过标准化流$G，得到一个新的向量$x$，让$x$的分布与人脸的分布相近，这样我们就可以生成任意张不同的人脸照片了。\n",
    "\n",
    "## 泛化（generalization）\n",
    "正确分类与训练集不同的新样本的能⼒。\n",
    "\n",
    "## 自回归模型（Autoregressive model）\n",
    "用同一变数$\\bm x$的之前各期，即$\\bm x_1$至$\\bm x_{t-1}$来预测本期$\\bm x_t$的表现，并假设它们为线性关系。\n",
    "\n",
    "定义：$$X_t = c+ \\sum_{i=1}^{p}\\psi _i X_{t-i}+\\epsilon _t$$\n",
    "含义：${\\displaystyle X}$的当期值等于一个或数个前期值的线性组合，加常数项，加随机误差。\n",
    "\n",
    "注意：c为常数项，$\\epsilon$是平均数为0，标准差为$\\sigma$的随机误差值，$\\psi$自相关系数，（是关键，如果小于0.5则该模型预测将极不准确）。\n",
    "\n",
    "## 深度基于能量的模型（deep Energy-based models）\n",
    "近年人气很高的模型，和标准化流或VAE，GAN，自回归类似，用于预测数据或生成近似的图像或声音的一种模型。\n",
    "\n",
    "## 先验分布（priori distribution）\n",
    "根据历史规律确定原因的概率分布即先验概率分布。（由历史求因）\n",
    "\n",
    "公式：$$p(因)$$\n",
    "$$p(\\theta)$$\n",
    "\n",
    "## 后验分布（posterior distribution）\n",
    "预先已知结果，根据结果预测原因的概率分布。（知果求因）\n",
    "\n",
    "公式：$$p(因|果)$$\n",
    "$$p(\\theta | x)$$\n",
    "\n",
    "“|”读作given，即给定的有意思。该式子表示因给定果的概率。\n",
    "\n",
    "## 似然估计（Likelihood Estimation）\n",
    "先定下原因，根据原因来估计结果的概率分布。（由因求果）\n",
    "根据原因来统计各种可能结果的概率即似然函数。\n",
    "\n",
    "公式：$$p(果|因)$$\n",
    "$$p(x | \\theta)$$\n",
    "\n",
    "## 贝叶斯公式\n",
    "$$p(A|B)=\\frac{p(B|A)\\times p(A)}{p(B)}$$\n",
    "\n",
    "$$后验概率=\\frac{似然估计\\times 先验概率}{evidence}$$\n",
    "\n",
    "$$p(\\theta |x)=\\frac{p(x|\\theta)\\times p(\\theta)}{p(x)}$$\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(1, 2, 2), dtype=int32, numpy=\n",
       "array([[[2, 2],\n",
       "        [2, 2]]])>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "81c9043bd05d90ad341e64bda8f89d527933a2e8877b3e37e2c924c4817d5fff"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
