{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 绪论\n",
    "+ 模式识别领域关注的是利⽤计算机算法⾃动发现数据中的规律，以及使⽤这些规律采取将数据分类等⾏动。\n",
    "+ ⼀个由N个数字$\\{x_1,\\dots,x_N\\}$组成的⼤的集合被叫做训练集（training set）\n",
    "+ 目标向量（target vector）$t$来表示标签。\n",
    "+ 预处理（pre-processed）将原始输入向量变换到新的变量空间，使得在新的变量空间中模式识别问题可以更容易地被解决。例如，通过将图像放大缩小至相同像素或居中处理后，使得每个数字类别的变化性降低。这种预处理也被叫做**特征抽取（feature extraction）**\n",
    "+ **监督学习**（supervised learning）训练数据的样本包含输⼊向量以及对应的⽬标向量的应⽤。\n",
    "    + 分类（classification）クラス分類。输出是有限数量离散标签中的一个。\n",
    "    + 回归（regression）输出由⼀个或者多个连续变量组成。\n",
    "+ **无监督学习（unsupervised learning）**训练数据由⼀组输⼊向量x组成，没有任何对应的⽬标值。\n",
    "    + 聚类（clustering）⽬标可能是发现数据中相似样本的分组。\n",
    "    + 密度估计（density estimation）决定输⼊空间中数据的分布。\n",
    "    + 数据可视化（visualization）把数据从高维空间投影到二维或者三维空间中。\n",
    "+ **强化学习**（reinforcement learning）在给定的条件下，找到合适的动作，使得奖励达到最⼤值。特点是没有给定最优输出的用例，学习必须在一系列的实验和错误中被发现。通常反馈学习是为了寻找一个探索（exploration）和利用（exploitation）的折中。**探索**用于寻找新的动作，**利用**用于系统使用已知能产生较高奖励的动作。\n",
    "    + 信用分配（credit assignment）奖励必须合理地分配给所有引起胜利的移动步骤。\n",
    "需要掌握其他学科的知识包括：概率论，决策论，信息论。\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1回归问题\n",
    "对于一个非线性的数据集来说，可以用一种很简单的数学模型来进行拟合。 \n",
    "$$y(x,\\bm\\omega)=\\omega_0+\\omega_1 x +\\omega_2 x^2 +\\dots + \\omega_M x^M=\\sum_{j=0}^{M}\\omega_j x^j$$\n",
    "\n",
    "优化这个模型是通过最小化误差函数（error function）的方法实现。因为这个模型中虽然自变量$x$是非线性的，但是其系数$\\omega$是线性的。该模型为的是获得正确的系数集合$\\bm \\omega$所以以$\\bm\\omega$为核心的最优化计算依然是线性的，所以该模型是**线性模型**，$M$在这里被称作阶数（order）。\n",
    "\n",
    "一个简单而又应用广泛的**误差函数**是每个数据点$x_n$的预测值$y(x_n,\\bm\\omega)$与目标值$t_n$的平方和。最小化以下多变量线性函数：\n",
    "$$E(\\bm \\omega)= \\frac{1}{2}\\sum_{n=1}^{N}\\{ y(x_n,\\bm\\omega)-t_n\\}^2$$\n",
    "\n",
    "验证该模型是否具备足够拟合样本的同时也应该使其具备足够的泛化而不要模型过于震荡产生过拟合（over-fitting）的现象。因此，我们需要在准备一个测试集来验证拟合后的模型对于其他样本（含有不同噪声干扰）的拟合程度。这里去计算误差的方式可以选择比较训练集的$E(\\bm \\omega ^*)$和测试集的$E(\\bm \\omega ^*)$或者可以直接使用**根均方**（RMS）误差更方便。\n",
    "$$E_{RMS}=\\sqrt{2E(\\bm \\omega^*)/N}$$\n",
    "\n",
    "**数据集规模越⼤，我们能够⽤来拟合数据的模型就越复杂（即越灵活），过拟合问题变得不那么严重**，此时，往往能获得更加优秀的泛化模型，但是大数据并不是必须的。经验：数据点的数量不应该⼩于模型的可调节参数的数量的若⼲倍（⽐如5或10）。\n",
    "\n",
    "控制过拟合现象的⼀种技术是正则化（regularization）。这种技术涉及到给误差函数$E(\\bm \\omega)$增加⼀个惩罚项，使得系数不会达到很⼤的值。惩罚项最简单的形式是采⽤所有系数的平⽅和。\n",
    "$$\\widetilde{E}(\\bm \\omega)= \\frac{1}{2}\\sum_{n=1}^{N}\\{ y(x_n,\\bm\\omega)-t_n\\}^2+\\frac{\\lambda}{2}\\left \\| \\bm\\omega \\right\\|^2$$\n",
    "\n",
    "$\\lambda$控制正则项的权重。通常系数w0从正则化项中省略，因为包含w0会使得结果依赖于⽬标变量原点的选择。在统计学的⽂献中被叫做收缩（shrinkage）⽅法。\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2概率论\n",
    "- 概率论存在两个基本规则**加法规则**和**乘法规则**\n",
    "- 只考虑某一种结果的概率被称为边缘概率（marginal probability）\n",
    "\n",
    "**sum rule** $$p(X)=\\sum_{Y}p(X,Y)$$\n",
    "**product rule**$$p(X,Y)=p(Y|X)p(X)$$\n",
    "**Bayess' theorem**パターン認識と機械学習のコア式$$p(Y|X)=\\frac{p(X|Y)p(Y)}{p(X)}$$\n",
    "**推导：**$$p(X)=\\sum_{Y}p(X|Y)p(Y)$$\n",
    "*使⽤数据对概率分布建模是统计模式识别的核⼼\n",
    "$p(X)$是先验概率，$p(X|Y)$是后验概率。如果$p(X,Y)=p(X)p(Y)$则$X和$Y$相互独立，即可以得出$p(Y|X)=p(Y)$\n",
    "\n",
    "#### 1.2.1概率密度\n",
    "考虑连续变量的相关概率的时候(即对于拥有无限种情况的随机事件来说如何求它发生的概率)，如果⼀个实值变量$x$的概率落在区间$(x, x +\\delta x)$的概率由$p(x)\\delta x$给出$（\\delta x \\rightarrow  0）$，那么$p(x)$叫做$x$的概率密度（probability density）。\n",
    "\n",
    "- **随机变量**\n",
    "可以看作是关联了概率值的变量。变量取每一个值的时候都有一定的概率。\n",
    "- **概率密度函数**\n",
    "把分布表推广到无限情况，就可以得到连续型随机变量的概率密度函数。此时，随机变量取每个具体的值的概率为0，但在落在每一点处的概率是有相对大小的，描述这个概念的，就是概率密度函数。你可以把这个想象成一个实心物体，在每一点处质量为0，但是有密度，即有相对质量大小。\n",
    "- **累计分布函数**\n",
    "位于区间$(-\\infty,z)$的$x$的概率由累积分布函数给出。\n",
    "$$P(z)=\\int_{-\\infty}^{z}p(x)dx$$\n",
    "**概率密度函数满足公式：**$$f(x)\\geq0$$ $$\\int_{+\\infty}^{-\\infty}f(x)dx = 1 $$\n",
    "- 常见的概率密度函数\n",
    "**高斯分布**$$f(x)=\\frac{1}{\\sqrt{2\\pi}\\sigma}e^{-\\frac{(x-\\mu)^2}{2\\sigma ^2}}$$\n",
    "\n",
    "**均匀分布（一様分布）**\n",
    "\n",
    "#### 期望和协方差（期待と分散）\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "7840536f5fdff62de99e3cfd20a767ab81e1456a34f77ddc3c201d1204379396"
  },
  "kernelspec": {
   "display_name": "Python 3.8.8 64-bit ('base': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.8.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
